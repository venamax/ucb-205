{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUBMISSION 1: How many rows are missing a value in the “State” column? Explain how you came up with the number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5377 rows were state information is missing. \n",
    "Looking at the facets for state we sorted by count and then realize that there were 5377 blanks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUBMISSION 2: How many rows with missing ZIP codes do you have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4362 blanks indicating that theere are 4362 rows were the zipcodes are missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUBMISSION 3: If you consider all ZIP codes less than 99999 valid ZIP codes, how many valid and invalid ZIP codes do you have, respectively?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created a new column named ValidZipCode and obtain the following results:\n",
    "Valid Zip Codes = 345175\n",
    "Invalid Zip Codes = 39323\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUBMISSION 5: Change the radius to 3.0. What happens? Do you want to merge any of the resulting matches?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes we want to merge results related to Alaska and California. However, we should not merge results related to Pakistan and Indonesia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUBMISSION 6: Change the block size to 2. Give two examples of new clusters that may be worthwhile merging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merged Alaska, California and Canada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUBMISSION 7: Explain in words what happens when you cluster the “place” column, and why you think that happened. What additional functionality could OpenRefine provide to possibly deal with the situation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering by place takes a long time because each place contains a lot of information which makes it difficul to compare with others. In this case is better to split the data into elements that can be more comparable. That's exactly what we did by extracting the state or country of the place in the location column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUBMISSION 8: Submit a representation of the resulting matrix from the Leveshtein edit distance calculation. The resulting value should be correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's the resulting matrix:\n",
      "[[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9.]\n",
      " [ 1.  0.  1.  2.  3.  4.  5.  6.  7.  8.]\n",
      " [ 2.  1.  0.  1.  2.  3.  4.  5.  6.  7.]\n",
      " [ 3.  2.  1.  1.  2.  3.  4.  5.  6.  7.]\n",
      " [ 4.  3.  2.  2.  1.  2.  3.  4.  5.  6.]\n",
      " [ 5.  4.  3.  3.  2.  1.  2.  3.  4.  5.]\n",
      " [ 6.  5.  4.  4.  3.  2.  1.  2.  3.  4.]\n",
      " [ 7.  6.  5.  5.  4.  3.  2.  1.  2.  3.]\n",
      " [ 8.  7.  6.  6.  5.  4.  3.  2.  1.  2.]\n",
      " [ 9.  8.  7.  7.  6.  5.  4.  3.  2.  1.]]\n",
      "\n",
      "Leveshtein distance is the value at d[9,9] = 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "h_word = [\"g\",\"u\",\"m\",\"b\",\"a\",\"r\",\"r\",\"e\",\"l\"]\n",
    "v_word = [\"g\",\"u\",\"n\",\"b\",\"a\",\"r\",\"r\",\"e\",\"l\"]\n",
    "\n",
    "def leveshtein(v_word, h_word):\n",
    "    n_rows = len(v_word)+1\n",
    "    m_columns = len(h_word)+1\n",
    "    d = np.zeros((n_rows, m_columns))\n",
    "    for m in range(m_columns):\n",
    "        for n in range(n_rows):\n",
    "            if m == 0: d[n,m]=n\n",
    "            elif n == 0: d[n,m]=m\n",
    "            elif v_word[n-1] == h_word[m-1]: \n",
    "                cost=0\n",
    "                d[n,m] = min (d[n-1,m]+1, d[n,m-1]+1, d[n-1, m-1]+cost)\n",
    "            else: \n",
    "                cost = 1\n",
    "                d[n,m] = min (d[n-1,m]+1, d[n,m-1]+1, d[n-1, m-1]+cost)\n",
    "    distance = d[n_rows-1,m_columns-1]\n",
    "    print \"Here's the resulting matrix:\"\n",
    "    print d\n",
    "    print\n",
    "    print \"Leveshtein distance is the value at d[%1d,%1d] = %1d\"%(n_rows-1, m_columns-1,distance )\n",
    "                 \n",
    "leveshtein(v_word, h_word)\n",
    "\n",
    "                 \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
